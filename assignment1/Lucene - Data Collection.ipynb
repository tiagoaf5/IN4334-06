{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the effects of ownership on software quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Lucene - A study case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this work is to replicate the [study](http://dl.acm.org/citation.cfm?doid=2025113.2025119) done by Bird et al., published in FSE'11. To replicate the work, we have selected [Lucene](https://lucene.apache.org/core/), a search engine written in java. Our goal is to see the results of a similar investigation on an OSS system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for performing the analysis is to analyse the data and create a **table** with the relevant information (i.e. *data collection*).\n",
    "\n",
    "In this study, we intend to relate certain ownership metrics and post-release bugs. The project under analysis was mainly developed in Java, which means that, most of the time, classes will be contained in a single file and each file will contain a single class. For this reason, the relation was analysed for each file in the project.\n",
    "\n",
    "This implies that our table will contain one row per file and a column per each ownership metric for that file, with one additional column containing the number of identified post release bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing what to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For defining a scope for the analysis, we opted to choose a release, compute the ownership metrics for all the files present in that release and determine which ones contained bugs. \n",
    "\n",
    "In order to choose a release to analyse, we went through a complete list of all Lucene issues until August, 2015. We then determined which of these issues identified bugs that had been fixed and chose to analyse the release version with the most fixed bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyse the files, we imported several python modules for handling files (and json files in particular) and set a path to our folder containing the issue files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "ISSUES_PATH = \"issue_LUCENE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we haven't the issues folder already we are going to download it. For this we will need the sh and os modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the issues successfully.\n"
     ]
    }
   ],
   "source": [
    "import sh\n",
    "import os\n",
    "\n",
    "if not os.path.exists(ISSUES_PATH):\n",
    "    sh.wget(\"-O\", \"issue_LUCENE.tar.bz2\", \n",
    "            \"https://drive.google.com/uc?id=0BzuWZdqy9QYwUHN6bThDU2VFN1k&export=download\") # download package\n",
    "    sh.tar(\"-jxvf\", \"issue_LUCENE.tar.bz2\") # extract package\n",
    "    sh.rm(\"issue_LUCENE.tar.bz2\") # remove package\n",
    "    print \"Downloaded the issues successfully.\"\n",
    "else:\n",
    "    print \"Issues folder already exists.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we retrieve all json files in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyfiles = [ f for f in listdir(ISSUES_PATH) if isfile(join(ISSUES_PATH,f)) and f.endswith(\".json\") ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we analyse all of them to determine which ones identify closed bugs with a *Fixed* resolution status, storing the bugs in a dictionary that maps from release version to bugs that affect this release. For convenience, we also store the resolution dates in a separate dictonary that maps from bugs to dates in order to later determine the most recent commit of the ones we will need to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "version_bugs = {}\n",
    "bug_fixed_dates = {}\n",
    "\n",
    "for f in onlyfiles:\n",
    "    with open(join(ISSUES_PATH,f)) as data_file:   \n",
    "        data = json.load(data_file)\n",
    "        if (data[\"fields\"][\"issuetype\"][\"name\"] == \"Bug\" and \n",
    "            data[\"fields\"][\"status\"][\"name\"] == \"Closed\" and \n",
    "            data[\"fields\"][\"resolution\"][\"name\"] == \"Fixed\"):\n",
    "            \n",
    "            bug_fixed_dates[data[\"key\"]] = data[\"fields\"][\"resolutiondate\"]\n",
    "            \n",
    "            versions = data[\"fields\"][\"versions\"]\n",
    "            for v in versions:\n",
    "                if version_bugs.has_key(v[\"name\"]):\n",
    "                    version_bugs[v[\"name\"]].append(data[\"key\"])\n",
    "                else:\n",
    "                    version_bugs[v[\"name\"]] = [data[\"key\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the dictionary, we iterate through it to determine which version has the most bugs and store the list of bugs in another dictonary which maps to an array which will contain the list of files affected by the bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version with most closed bugs: 4.0-ALPHA with 179 bugs.\n"
     ]
    }
   ],
   "source": [
    "most_bugs = 0\n",
    "buggy_version = \"\"\n",
    "\n",
    "for k,v in version_bugs.iteritems():\n",
    "    if len(v) > most_bugs:\n",
    "        most_bugs = len(v)\n",
    "        buggy_version = k\n",
    "        \n",
    "bugs = {}\n",
    "\n",
    "for b in version_bugs[buggy_version]:\n",
    "    bugs[b] = []\n",
    "\n",
    "print \"Version with most closed bugs:\", buggy_version , \"with\", len (version_bugs[buggy_version]), \"bugs.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is finding the date of the most recent bug fix that affects the chosen version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The day of the most recent bug fix is 2014-01-24\n"
     ]
    }
   ],
   "source": [
    "latest_date = \"1999\"   # date for the most recent bug fix\n",
    "\n",
    "for b in bugs:\n",
    "    latest_date = (bug_fixed_dates[b] if bug_fixed_dates[b] > latest_date else latest_date)\n",
    "\n",
    "latest_date = latest_date[:10]\n",
    "\n",
    "print \"The day of the most recent bug fix is\", latest_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ownership metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which files and bugs we want to analyse, we can start going through repository data to extract the relevant metrics.\n",
    "\n",
    "Firstly, we must first clone the repository and checkout the version we chose to analyse (which we previously determined to be version 4.0-ALPHA). \n",
    "We import the re module which will be useful for extracting information from commits through regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkout of tag lucene_solr_4_0_0_ALPHA.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "if not os.path.exists(\"lucene-solr\"):\n",
    "    sh.git.clone(\"https://github.com/apache/lucene-solr.git\")\n",
    "    \n",
    "git = sh.git.bake(_cwd='lucene-solr') #specify repository directory\n",
    "\n",
    "git.checkout(\"tags/lucene_solr_4_0_0_ALPHA\")\n",
    "\n",
    "print \"Checkout of tag lucene_solr_4_0_0_ALPHA.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract a list of files in the repository with the git ls-files command. We are only interested in java files so we only want files ending in \".java\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 3851 java files.\n"
     ]
    }
   ],
   "source": [
    "files = [ f for f in git(\"ls-files\").split(\"\\n\") if f.endswith(\".java\") ]\n",
    "print \"We found\", len(files), \"java files.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list of files, we extract information relative to the contributors of each one using the git log command to retrieve the list of contributors. With the output generated by this command it is then necessary to sort and count the occorrunces of each contributor. To achieve this, the *sort* and *uniq* shell commands were used.\n",
    "\n",
    "Knowing how many contributions each contributor did, it is then possible to determine the ownership metrics for each file relating to:\n",
    "* **total**: total number of contributors\n",
    "* **major**: number of major contributors (5% or more of total contributions)\n",
    "* **minor**: number of minor contributors (less than 5% of total contributions)\n",
    "* **ownership**: maximum ownership of a contributor over the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading repository... ...finished reading in 10 minutes and 50 seconds.\n"
     ]
    }
   ],
   "source": [
    "print \"Reading repository...\",\n",
    "start = time.time()\n",
    "\n",
    "table = {}\n",
    "\n",
    "for f in files:\n",
    "    contributors_data = filter(None, sh.uniq(sh.sort(git.log(\"--format=format:%an\", f)), \"-c\").split(\"\\n\"))\n",
    "    contributors = []\n",
    "    total = 0\n",
    "    max_ownership = 0\n",
    "    minor = 0\n",
    "    major = 0\n",
    "    \n",
    "    for a in contributors_data:\n",
    "        num = int(re.search(\"[0-9]+\", a).group(0))\n",
    "        name = re.search(\"([A-z]+\\s*)+\", a).group(0)\n",
    "        total += num\n",
    "        max_ownership = num if num > max_ownership else max_ownership\n",
    "        contributors.append((name,num))\n",
    "    \n",
    "    for a in contributors:\n",
    "\n",
    "        if a[1] * 1.0 / total >= 0.05:\n",
    "            major += 1\n",
    "        else:\n",
    "            minor += 1\n",
    "        \n",
    "    table[f]= {\"minor\": minor, \n",
    "               \"major\": major, \n",
    "               \"total\": minor + major, \n",
    "               \"ownership\": (float(\"{0:.2f}\".format(max_ownership * 1.0 / total * 100))),\n",
    "               \"num_of_bugs\":0}\n",
    "\n",
    "print \"...finished reading\", time.strftime('in %M minutes and %S seconds.', time.gmtime(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finding commits that fix bugs of the chosen release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that is left is to find how many bugs each file has by analysing the commits that fix each bug.\n",
    "\n",
    "Using the latest date we found when obtaining the bug list from the issue files, we first determine the latest commit that fixes a bug for this version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash of the last commit before latest bug fix: ba560c7484c1df260ae78b414749fa81af998231\n"
     ]
    }
   ],
   "source": [
    "shaLatest = (git(\"rev-list\",\"-n 1\",\"--before=\\\"\" + latest_date + \"23:59\\\"\",\"trunk\")).stdout[:-1]\n",
    "print \"Hash of the last commit before latest bug fix:\", shaLatest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now retrieve the full list of commits that we need to analyse for finding bug fixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 7342 commits to analyse.\n"
     ]
    }
   ],
   "source": [
    "commit_list = filter(None, git(\"rev-list\", \"--topo-order\", \"HEAD..\" + shaLatest).split(\"\\n\"))\n",
    "print \"We have\", len(commit_list), \"commits to analyse.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search for commits that contain references to Lucene issues and check if we have a bug with the same id. If there is a match, we retrieve the list of files modified by that commit and store them in our *bugs-to-affected_files* dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified fixes for 32 out of 179 in 03 minutes and 35 seconds.\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "\n",
    "for commit in commit_list:\n",
    "    message = str(git.log(\"--format=%B\", \"-n 1\", commit))\n",
    "    match = re.search(\"LUCENE-[0-9]+\", message)\n",
    "    \n",
    "    if match:\n",
    "        key = match.group(0).strip()\n",
    "        if key in bugs: \n",
    "            files_changed = filter(None, git(\"diff-tree\", \"--no-commit-id\", \"--name-only\", \"-r\", commit).split(\"\\n\"))\n",
    "            bugs[key] = files_changed\n",
    "\n",
    "print \"Identified fixes for\", len ({k for (k,v) in bugs.iteritems() if len(v) > 0}) ,\"out of\", str(len(bugs)), \n",
    "print time.strftime('in %M minutes and %S seconds.', time.gmtime(time.time() - start1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now update our table with information relating to the number of bugs by incrementing the variable for each file that was changed in a bugfix commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, value in bugs.iteritems():\n",
    "    if len(value) > 0:\n",
    "        for file in value:\n",
    "            if file in table:\n",
    "                table[file][\"num_of_bugs\"] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all that is left to finish the data collection phase is generating a csv file with all the relevant information. A *data.csv* file is created and the table we generated is written with each entry of the table corresponding to a line in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as data.csv.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data.csv\", \"w\")\n",
    "f.write(\"file_name, minor, major, total, ownership, num_of_bugs\\n\")\n",
    "\n",
    "for k,v in table.iteritems():\n",
    "    f.write(k + \",\" + str(v[\"minor\"]) + \", \" + str(v[\"major\"]) + \", \" + str(v[\"total\"]) + \n",
    "            \", \" + str(v[\"ownership\"]) + \"%, \" + str(v[\"num_of_bugs\"]) +\"\\n\")\n",
    "\n",
    "f.close()\n",
    "\n",
    "print \"CSV file saved as data.csv.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
